<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4001/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4001/" rel="alternate" type="text/html" /><updated>2023-07-07T15:04:44+08:00</updated><id>http://localhost:4001/feed.xml</id><title type="html">In-Between</title><subtitle>A journey of recognition, appreciation and creation. This blog focuses on translating mathematical concepts  into natural language. It helps understand where the concept comes from, what it exactly means and how we apply.</subtitle><entry><title type="html">Hull White Model</title><link href="http://localhost:4001/math/2023/06/10/Hull-White-Model.html" rel="alternate" type="text/html" title="Hull White Model" /><published>2023-06-10T16:20:46+08:00</published><updated>2023-06-10T16:20:46+08:00</updated><id>http://localhost:4001/math/2023/06/10/Hull-White-Model</id><content type="html" xml:base="http://localhost:4001/math/2023/06/10/Hull-White-Model.html">&lt;p&gt;The fixed income market offers bonds, and the interest rate derivatives are the pre-eminent market among the OTC transactions. This contributes from the nature of corporate financing.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Global fixed income markets outstanding is $126.9 trillion in 2021, while global equity market capitalization is \$124.4 trilion in 2021.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The notional value of outstanding interest rate derivative is $440 trillion, while the total derivative is \$610 trillion in 2021.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The term structure is the specific part from derivatives on equity market. Hull White model is one of the earliest no-arbitrage model that can model the term structure. It is popular because it is non-aribtrage and relatively easy to calibrate.&lt;/p&gt;

&lt;p&gt;It models the short rate and the price of a derivative is a function of the entire yield curve.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Short Rate&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let $P(t,T)$ be a bond price with the maturity at $T$. The relationship with forward rate $f(t,T)$ is as below.&lt;/p&gt;

&lt;p&gt;$P(t,T) = e^{-\int_t^T{f(t,u)du}}$&lt;/p&gt;

&lt;p&gt;The forward rate is the rate over the period of $[t,T]$ and observed from market if $t$ is the current time point. The short rate $r_T$ is $f(T,T)$, a future instantenous rate.&lt;/p&gt;

&lt;p&gt;$P(t,T) = \mathbb{E}e^{-\int_t^T{r_u du}}$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hull White Model&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$dr(t) = k[\theta(t) - r(t)]dt +\sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;where $k$ is the mean reversion rate. The parameters of $k$ and $\sigma(t)$ combine to creat the effective volatility.&lt;/p&gt;

&lt;p&gt;Let $r(t) = x(t) +\phi(t)$ and $\theta(t) = \phi(t) + \frac{1}{k}\frac{d\phi(t)}{dt}$, then the above process becomes the below&lt;/p&gt;

&lt;p&gt;$dx(t) = -kx(t)dt + \sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;Solve it by the following steps:&lt;/p&gt;

&lt;p&gt;$dx(t) + kx(t)dt = \sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;$e^{kt}(dx_t + kx_tdt) = e^{kt}\sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;$de^{kt}x_t =e^{kt}\sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;Integrate by $t$ from $v$ to $u$,&lt;/p&gt;

&lt;p&gt;$\int_v^u de^{kt}x_{t} =\int_v^u e^{kt}\sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;$x(u) = e^{-k(u-v)}x(v) + \int_v^u e^{-k(u-t)}\sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;$r(u) = \phi(u) + e^{-k(u-v)}x(v) + \int_v^u e^{-k(u-t)}\sigma(t)dW(t)$&lt;/p&gt;

&lt;p&gt;Replace the variable $t$ with $s$ and $v$ with $t$.&lt;/p&gt;

&lt;p&gt;$r(u) = \phi(u) + e^{-k(u-t)}x(t) + \int_t^u e^{-k(u-s)}\sigma(s)dW(s)$&lt;/p&gt;

&lt;p&gt;Integrate by $u$ from $t$ to $T$,&lt;/p&gt;

&lt;p&gt;$\int_{t}^T r(u) du = \int_{t}^T \phi(u) du + \int_{t}^T e^{-k(u-t)}x(t) du+ \int_{t}^T \int_t^u e^{-k(u-s)}\sigma(s)dW(s)du$&lt;/p&gt;

&lt;p&gt;$\int_t^T r(u) du = \int_t^T \phi(u) du + \beta(t,T) x(t) + \int_t^T \sigma(s)\beta(s,T)dW(s)$,&lt;/p&gt;

&lt;p&gt;where $\beta(t,T) = \frac{1}{k}(1-e^{-k(T-t)})$&lt;/p&gt;

&lt;p&gt;So the bond price is&lt;/p&gt;

&lt;p&gt;$P(t,T) = \mathbb{E} e^{-\int_t^T r_{u} du}$&lt;/p&gt;

&lt;p&gt;$P(t,T) = \mathbb{E} e^{-[\int_t^T \phi(u) du + \beta(t,T) x(t) + \int_t^T \sigma(s)\beta(s,T)dW(s)]}$&lt;/p&gt;

&lt;p&gt;By Exponential Martingale Property,&lt;/p&gt;

&lt;p&gt;$P(t,T) = e^{-[\int_t^T \phi(u) du + \beta(t,T) x(t) - \frac{1}{2}\int_t^T \sigma^2(s)\beta^2(s,T)ds]}$&lt;/p&gt;

&lt;p&gt;$dP(t,T) = P(t,T)*[\phi(t)dt - d(\beta(t,T)x(t)) - \frac{1}{2}\sigma^2(t)\beta^2(t,T)dt]$&lt;/p&gt;

&lt;p&gt;By Ito’s Lemma on $\beta(t,T)x(t)$,&lt;/p&gt;

&lt;p&gt;$d\beta(t,T)x(t) = x(t)d\beta(t,T) + \beta(t,T)dx(t) + \frac{1}{2} \beta^2(t,T)dx^2(t)$
$= x(t)dt -\beta(t,T)\sigma(t)dW(t) + \frac{1}{2}\sigma^2(t)\beta^2(t,T)dt$&lt;/p&gt;

&lt;p&gt;$dP(t,T) = P(t,T) * [r(t)dt - \sigma(t)\beta(t,T)dW(t)]$&lt;/p&gt;

&lt;p&gt;The above formula give the relationship between the short rate $r(t)$ and the bond price $P(t,T)$. Based on it, the calibration of the multiplication of $\sigma(t)$ and $\beta(t,T)$ (a function of $k$) is straightforward from the observed bond price and short rate from caplet or swaption. The mean reversion rate $k$ usually choose from empirical value on the order of 0.0 to 0.1.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Reference: Choong Tze Chua, Dean Foster, Krishna Ramaswamy and Robert Stine, A Dynamic Model for the Forward Curve, 2005.&lt;/p&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">The fixed income market offers bonds, and the interest rate derivatives are the pre-eminent market among the OTC transactions. This contributes from the nature of corporate financing.</summary></entry><entry><title type="html">What is Risk Neutral</title><link href="http://localhost:4001/math/2023/01/10/What-is-Risk-Neutral.html" rel="alternate" type="text/html" title="What is Risk Neutral" /><published>2023-01-10T16:20:46+08:00</published><updated>2023-01-10T16:20:46+08:00</updated><id>http://localhost:4001/math/2023/01/10/What-is-Risk-Neutral</id><content type="html" xml:base="http://localhost:4001/math/2023/01/10/What-is-Risk-Neutral.html">&lt;p&gt;From the words Risk Neutral, it tells that the investor has no risk preference. That’s correct, but what does it mean? It means two practical points below to me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Expected rate of return is risk free rate&lt;/li&gt;
  &lt;li&gt;The spot price is the expectation of the asset/underlying&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That sounds great for pricing any contingent claim as the asset/underlying is easily predicted. But wait, for a stock, why is the expected rate of return risk free rate? It doesn’t have to, but adjusting the probability can make it.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Rate of return&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;16%&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Rate of return&lt;/th&gt;
      &lt;th&gt;3%&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Prob $p_1$: 56%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Prob $p_1$: 50%&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Prob $p_2$: 44%&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Prob $p_2$: 50%&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Expected price&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.97&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Expected price&lt;/td&gt;
      &lt;td&gt;0.97&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Although the probability is adjusted, the market expected price still matches. In practice, the probability is derived from market price and this process is called calibration.&lt;/p&gt;

&lt;p&gt;Let us introduce some concepts in non-technique way.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Numeraire&lt;/strong&gt;: a positive non-dividend paying asset, which can be seen as a benchmark asset&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Measure&lt;/strong&gt;: a probability distribution&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Change of measure&lt;/strong&gt;: change the mean of the distribution, but the volatility keeps.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The rate of return and the probability can be adjusted, in the above language, the benchmark (Numeraire) and the probability distribution (Measure) can be changed for the calculation convenience.&lt;/p&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">From the words Risk Neutral, it tells that the investor has no risk preference. That’s correct, but what does it mean? It means two practical points below to me:</summary></entry><entry><title type="html">Ito’s Lemma</title><link href="http://localhost:4001/math/2022/10/10/Ito's-Lemma.html" rel="alternate" type="text/html" title="Ito’s Lemma" /><published>2022-10-10T16:20:46+08:00</published><updated>2022-10-10T16:20:46+08:00</updated><id>http://localhost:4001/math/2022/10/10/Ito&apos;s-Lemma</id><content type="html" xml:base="http://localhost:4001/math/2022/10/10/Ito&apos;s-Lemma.html">&lt;p&gt;Ito’s Lemma is the chain rule in stochastic process. It is foundamental technique to simplify stochsastic process formula.&lt;/p&gt;

&lt;p&gt;Ito’s Lemma is a differential form of Ito-Doeblin formula. Essentially they are the same but in different forms.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;W. Doeblin was a French soldier on the German Front back to 1940’s. His work was mailed to French National Academy of Science in 1940 and he died shortly after that. The document only discovered and published in 2000.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Ito’s Lemma&lt;/strong&gt;
Let $W(t)$ be a Brownian motion and $f(t,W(t))$ be a function with the existing of $f_t, f_x$ and $f_{xx}$.&lt;/p&gt;

&lt;p&gt;$df(t,W(t)) = f_t(t,W(t))dt + f_x(t,W(t))dW(t)+ \frac{1}{2}f_{xx}(t,W(t))dt$&lt;/p&gt;

&lt;p&gt;I will see how Ito’s Lemma works to derive a simple version of Fokker-Planck Equation.&lt;/p&gt;

&lt;p&gt;Assume the function $f(X_t)$, we have&lt;/p&gt;

&lt;p&gt;$df = f_xdX_t + \frac{1}{2}f_{xx}dX_t^2$&lt;/p&gt;

&lt;p&gt;If $X_t = W(t)$, then&lt;/p&gt;

&lt;p&gt;$df = f_xdW(t) + \frac{1}{2}f_{xx}dt$&lt;/p&gt;

&lt;p&gt;Take the expectation on both sides, the stochastic part disappears.&lt;/p&gt;

&lt;p&gt;$E[df] = \frac{1}{2}E[f_{xx}]dt$&lt;/p&gt;

&lt;p&gt;Move $dt$ to the left side,&lt;/p&gt;

&lt;p&gt;$\frac{d}{dt}E[f] = \frac{1}{2}E[f_{xx}]$&lt;/p&gt;

&lt;p&gt;Assume the density function of $f(X_t)$ is $p(x,t)$ and follow the chain rule, we have the simplified version of Fokker-Planck Equation.&lt;/p&gt;

&lt;p&gt;$\frac{\partial{p(x,t)}}{\partial{t}} = \frac{1}{2}\frac{\partial{^2p(x,t)}}{\partial{x^2}}$&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If $dX_t = \mu(X_t)dt + \sigma(X_t)dW(t)$, then the Fokk-Plank Equation is $\frac{\partial{p(x,t)}}{\partial{t}} = (-\frac{\partial{}}{\partial{x}} \mu(x) + \frac{1}{2}\frac{\partial{^2}}{\partial{x^2}}\sigma^2(x))p(x,t)$&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">Ito’s Lemma is the chain rule in stochastic process. It is foundamental technique to simplify stochsastic process formula.</summary></entry><entry><title type="html">Integral in Stochastic Calculus</title><link href="http://localhost:4001/math/2021/09/08/Integral-in-Stochastic-Calculus.html" rel="alternate" type="text/html" title="Integral in Stochastic Calculus" /><published>2021-09-08T16:20:46+08:00</published><updated>2021-09-08T16:20:46+08:00</updated><id>http://localhost:4001/math/2021/09/08/Integral-in-Stochastic-Calculus</id><content type="html" xml:base="http://localhost:4001/math/2021/09/08/Integral-in-Stochastic-Calculus.html">&lt;p&gt;Preliminary article: &lt;a href=&quot;/math/2021/02/14/Basic-of-Stochastic-Calculus.html&quot;&gt;Basic of Stochastic Calculus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Brownian Motion $ W(t) $ is not differentiable, however similar to the definition of quadratic variation, the integral of $W(t)$ can be defined as the sum of value in each partition of the time period, which is called Ito’s Integral:
\(I(t) = \int_{0}^{t} \Delta (u) dW(u) = \lim_{n \to \infty}\sum_{j=0}^{k-1} \Delta(t_j)[W(t_{j+1})-W(t_j)]\)&lt;/p&gt;

&lt;p&gt;The Ito’s integral satifies the following properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;(Maringale)&lt;/strong&gt; $I(t)$ is a martingale&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;(Ito’s isometry)&lt;/strong&gt; $\mathbb{E}I^2(t) = \mathbb{E}\int_{0}^t\Delta^2(u)du$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;(Quadratic variation)&lt;/strong&gt; $[I,I](t) = \int_{0}^t\Delta^2(u)du$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is good to notice the difference between quadratic variation and the variance of the process $I(t)$. The quadratic variation is path-dependent, while the variance of $I(t)$ is an average over all possible paths of the quadratic variation.&lt;/p&gt;

&lt;p&gt;Similar to Riemann integral, the Ito’s integral is calculated from a partition of a time interval $[0,t]$. What does the Brownian motion $W(t)$ do in the integral? For illustration purpose, assume that $\Delta (t)$ is not a function of $W(t)$ but just $t$. The integral will be similar to the graph as below and takes into the consideration of the distribution of $W(t)$ at the time point $t$. In other words, the integral is a multiplication of $\Delta (t)$ and a normal distributed density along the time $t$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/image/Integral_Ito.png&quot; alt=&quot;Integral_Ito&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the case that $\Delta (t)$ is a function of $W(t)$, which is much common in stochastic calculus, it is more complicated but it follows the idea elaborated above.&lt;/p&gt;

&lt;p&gt;When we are given a stochastic process, how can we integrate it into an expressive equation? 
\(dS(t) = a(t) dt + b(t) dW(t)\)
The answer is that we don’t need to do it, but we should be used to leave it and view it as some distribution, usually it is normal distribution. Let’s explain it.&lt;/p&gt;

\[\begin{align*}
 S(T) &amp;amp;= S(0) + \int_{0}^{T} a(t) dt &amp;amp;+ \int_{0}^{T} b(t) dW(t) \\
    &amp;amp;= S(0) + \int_{0}^{T} a(t) dt &amp;amp;+ \lim_{n-&amp;gt; \infty}\sum_{i=1}^{n} b(t_{i-1}) (W(t_{i}) - W(t_{i-1})) \\
    &amp;amp;= [\text{mean}] &amp;amp;+ [\text{sum of independent normal distributions}] \\
    &amp;amp;= [\text{mean}] &amp;amp;+ [\text{a normal distribution}]
\end{align*}\]

&lt;p&gt;From the above, there are two parts: the ‘mean’ part is ordinary calculus; and the ‘normal distribution’ part. So what is $S(T)$? It’s a normal distribution with the mean $S(0) + \int_{0}^{T} a(t) dt$ and the derivation of $\int_{0}^{T} b(t) dW(t)$. If $b(t)$ is constant $b$, the latter part is $b W(T)$ with the deviation of $b \sqrt{t}$.&lt;/p&gt;

&lt;p&gt;If $b(t)$ is $W(t)$, we have
\(\int_{0}^{T} W(t) dW(t) = \frac{1}{2} W^2(T) - \frac{1}{2}T\)
If $b(t)$ is in other form, the integral can be get similarly to Riemann sum, by $\lim_{n-&amp;gt; \infty}\sum_{i=1}^{n} b(t_{i-1}) (W(t_{i}) - W(t_{i-1}))$.&lt;/p&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">Preliminary article: Basic of Stochastic Calculus</summary></entry><entry><title type="html">Decision Tree</title><link href="http://localhost:4001/math/2021/03/25/Decision-Tree.html" rel="alternate" type="text/html" title="Decision Tree" /><published>2021-03-25T08:20:46+08:00</published><updated>2021-03-25T08:20:46+08:00</updated><id>http://localhost:4001/math/2021/03/25/Decision-Tree</id><content type="html" xml:base="http://localhost:4001/math/2021/03/25/Decision-Tree.html">&lt;p&gt;Decision Tree is a supervised learning approach. The model is a predictive model and usually for classification, where the target variable is discrete. Although it also can be used for continuous target variable, the prediction is less effective.&lt;/p&gt;

&lt;p&gt;The decision tree is intuitive and usually the softwares provide the visualisation. One benefit of the process is that it can handle the dependent variables, both discrete and continous.&lt;/p&gt;

&lt;p&gt;Let’s check one example, the table below lists the factors that affect people’s decision to play golf.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/image/Golf_dataset.png&quot; alt=&quot;Golf_dataset&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From the table, it is not straightforward how people make the decision. However, the Decision Tree algorithm can give the graph below and I believe it is much clear to you.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/image/Decision_tree_model.png&quot; alt=&quot;Decision_tree&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Yes, that is Decision Tree. The idea is natural, as it is the same as one of human thinking process. Decision trees are commonly used to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning to do classification.&lt;/p&gt;

&lt;p&gt;The mystery I guess is that how each branch is decided. Let’s check the mathematics and algorithm behind. In mathematics part, we will introduce &lt;strong&gt;Impurity&lt;/strong&gt; concept and in algorithm part, you can see how impurity is applied to achieve the goal.&lt;/p&gt;

&lt;h2 id=&quot;mathematics-behind&quot;&gt;Mathematics Behind&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Impurity&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Impurity is a measure of the homogeneity of the labels, in other words, determines how well a decision tree splits.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Entropy&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Entropy is a measure of chaos in the dataset, with weighted entropy to evaluate the splits.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;p&gt;CART (Classification and Regression Trees) — This makes use of Gini impurity as the metric.
ID3 (Iterative Dichotomiser 3) — This uses entropy and information gain as metric.&lt;/p&gt;

&lt;p&gt;Gini impurity is defined as&lt;/p&gt;

&lt;p&gt;$Impurity = 1 - Gini = 1 - \sum_i{P_i^2}$&lt;/p&gt;

&lt;p&gt;where $P_i$ is the probability of one category in the group/subgroup.&lt;/p&gt;

&lt;p&gt;Group:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Play: 9, Prob: 9/14&lt;/li&gt;
  &lt;li&gt;Don’t Play: 5, Prob: 5/14&lt;/li&gt;
  &lt;li&gt;Gini = $(9/14)^2+ (5/14)^2$&lt;/li&gt;
  &lt;li&gt;Impurity = 1 - Gini = 1- 0.54 = 0.46&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Subgroup (weighted impurity):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Outlook = 5/14* Sunny Impurity + 4/14* Overcast Impurity + 5/14 * Rain Impurity = 5/14 * 0.48 + 4/14 * 0 + 5/14 * 0.48 = 0.34&lt;/li&gt;
  &lt;li&gt;Windy = 6/14 * Windy Impurity + 8/14 * Non-windy Impurity = 6/14 * 0.38 + 8/14 * 0.5 = 0.43&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When it comes to continuous variables, the technique of regression tree is used in the algorithm, like CART, ID3. The regression tree determins threshold(s) by the same measure of impurity. There are different methods to determine the threshold(s). More details can be found in the paper &lt;em&gt;Efficient Determination of Dynamic Split Points in a Decision Tree&lt;/em&gt; by Microsoft Research.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the threshold is 85, Humidity = 0.44&lt;/li&gt;
  &lt;li&gt;If the threshold is 80, Humidity = 0.39&lt;/li&gt;
  &lt;li&gt;If the threshold is 70, Humidity = 0.45&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Similar regression tree can be done on the feature Temperature. However, you will find the feature Outlook mostly reduces the impurity. Thus it is chosen as the first top leaf on the tree. Similar steps will produce the children leaves.&lt;/p&gt;

&lt;h2 id=&quot;local-optimum&quot;&gt;Local optimum&lt;/h2&gt;

&lt;p&gt;It is easy to note that the locally optimal decisions are made at each leaf in the above algorithms. This also makes the decision tree is not robust, i.e. a samll change in the training data can result in a large change in the tree. In this case, you might consider other algorithms such as Dual Information Distance (DID).&lt;/p&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">Decision Tree is a supervised learning approach. The model is a predictive model and usually for classification, where the target variable is discrete. Although it also can be used for continuous target variable, the prediction is less effective.</summary></entry><entry><title type="html">Basic of Machine Learning</title><link href="http://localhost:4001/math/2021/02/15/Basic-of-Machine-Learning.html" rel="alternate" type="text/html" title="Basic of Machine Learning" /><published>2021-02-15T09:20:46+08:00</published><updated>2021-02-15T09:20:46+08:00</updated><id>http://localhost:4001/math/2021/02/15/Basic-of-Machine-Learning</id><content type="html" xml:base="http://localhost:4001/math/2021/02/15/Basic-of-Machine-Learning.html">&lt;p&gt;This article helps you understand the concept of Machine Laerning. It comes in the format of FAQ (Frequently Asked Questions), and focuses on the mysteries that I had during the study of machine learning. The general ideas of algorithms are also introduced here but not in details of mathematical basic or implementation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What’s the ML (Machine Learning)?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ML: the computer algorithm with data feed to achieve self-evolving solution. A video of the introduction to Machine Learning? (&lt;a href=&quot;https://youtu.be/QghjaS0WQQU&quot;&gt;2 minutes video&lt;/a&gt;)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Machine learning is the study of computer algorithms that allow computer programs to automatically improve through experience.&lt;/p&gt;

  &lt;p&gt;— by Tom Mitchell, McGraw Hill, 1997&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;What’s the difference from AI (Artificial Intelligence)?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;AI: general concept to allow machines to act like humans. In this sense, AI is the intergated product of “smart” machine, which can include the algorithm, the soft/hard-ware and the interaction with human or environment.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What’s the difference from Statistics / Data Mining?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The common part is data driven. Statistics / Data Mining study the patterns, relationships or anomalies of data / large data set. This requires human intervention and decision making. Machine Learning fully/partially cuts the human intervention.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The classification of Machine Learning&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Supervised Learning - labelled&lt;/li&gt;
  &lt;li&gt;Unsupervised Learning - non-labelled&lt;/li&gt;
  &lt;li&gt;Reinforcement Learning - interaction/dynamics to maximize the cumulative reward (e.g.Go game, the next step depends on the interaction of the opponent, and there is no sure win until the last stage but the highest chance to win.) A fun example is the &lt;a href=&quot;https://youtu.be/qv6UVOQ0F44&quot;&gt;Mario video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Deep Learning, also known as deep neural learning or deep neural network.&lt;/em&gt;&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;&lt;em&gt;It’s not one of the classification of problems that Machine Learning is going to solve. Instead, Deep Learning is an algorithm of neural network to solve any problem it can.&lt;/em&gt;&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;The common algorithms&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Regression - &lt;em&gt;linear relationships with (transformed) features&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/math/2021/03/25/Decision-Tree.html&quot;&gt;Decision Tree&lt;/a&gt; - &lt;em&gt;flowchart with conditions on features&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;K-Nearest Neighbors (KNN)&lt;/li&gt;
  &lt;li&gt;Support Vector Machine (SVM)&lt;/li&gt;
  &lt;li&gt;Ensemble Learning
    &lt;ul&gt;
      &lt;li&gt;Random Forest&lt;/li&gt;
      &lt;li&gt;Bagging: Boostrap sampling&lt;/li&gt;
      &lt;li&gt;Gradient Boosting (GBT)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Neural Network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because of the requirement of little human invention, the criteria of justifying a model becomes very importance and must be quantifiable/measurable. You will see the measurement how good the model is plays a very important part of Machine Learning. Take regression as an example, in Statistics, the practitioner focuses on the relationship between dependent variable and independent variables/features and further the economic explanation/understanding. However, in Machine Learning, this relationship is driven by the goodness of fitting and the prediction power gives the final call.&lt;/p&gt;

&lt;p&gt;The evaluation of the fitting is leveraged by &lt;strong&gt;cost function&lt;/strong&gt;, which is explicitely defined in mathematical formula. The cost function can be the gap between actual values and predicted values, also, it can be the quantifiable penality of each solution.&lt;/p&gt;

&lt;p&gt;Now we have the problem, the algorithm and the well-defined cost function. How will the algorithm achieve the final solution, or evolve by on-going fed-in data/experience? The answer is &lt;strong&gt;Optimizer&lt;/strong&gt;, which can be understood as the tool you use to achieve the task. The optimizer determines the efficiency of the model.&lt;/p&gt;

&lt;p&gt;To summarise, we cite from Tom Mitchell again on how he describe well-posed learning problem.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.&lt;/p&gt;

  &lt;p&gt;— by Tom Mitchell, 1998&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So the key elements to solve a problem by Machine Learning are&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Task/Problem&lt;/li&gt;
  &lt;li&gt;Data/Experience&lt;/li&gt;
  &lt;li&gt;Performance Measure/Cost function
    &lt;ul&gt;
      &lt;li&gt;This can be part of algorithm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Algorithm&lt;/li&gt;
  &lt;li&gt;Optimizer&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">This article helps you understand the concept of Machine Laerning. It comes in the format of FAQ (Frequently Asked Questions), and focuses on the mysteries that I had during the study of machine learning. The general ideas of algorithms are also introduced here but not in details of mathematical basic or implementation.</summary></entry><entry><title type="html">Basic of Stochastic Calculus</title><link href="http://localhost:4001/math/2021/02/14/Basic-of-Stochastic-Calculus.html" rel="alternate" type="text/html" title="Basic of Stochastic Calculus" /><published>2021-02-14T16:20:46+08:00</published><updated>2021-02-14T16:20:46+08:00</updated><id>http://localhost:4001/math/2021/02/14/Basic-of-Stochastic-Calculus</id><content type="html" xml:base="http://localhost:4001/math/2021/02/14/Basic-of-Stochastic-Calculus.html">&lt;h2 id=&quot;brownian-motion&quot;&gt;Brownian Motion&lt;/h2&gt;

&lt;p&gt;In discrete format, the concept of random walk is relatively easy to accept, one time one uniform step, up or down. In the macroworld, there is seldom change/motion which is discrete. The Brownian Motion can be seen as the continuous motion with uniform speed, where the direction is up or down and can change anytime. Based on this understanding, naturally there are three charaticstics of the Brownian Motion $W(t), t\geq 0$:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$W(0) = 0$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$ W([t_1,t_2]) = W(t_2) - W(t_1) $ is independent from $W([t_i,t_j])$ if the time is not overlapped&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$ W([t_1,t_2]) $ is normal distributed, i.e. $N(0,t_2-t_1)$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above is also how the Brownian Motion is defined. Just a word on probability space $(\Omega, \mathcal{F}, \mathbb{P})$, and this can simply understand as (All the outcomes, Rule, Probability). Specifically, “All the outcomes” mean all the Brownian Motion paths.&lt;/p&gt;

&lt;p&gt;For the problem of Brownian Motion, it is solved or becomes easier if the form of $W([t_1,t_2])$ emerges.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Martingale Property&lt;/strong&gt;
\(\mathbb{E}[W(t)|\mathcal{F}(s)] = W(s), s&amp;lt; t\)
The martingale property is important but it might be more useful to check Exponential Martingale Property and Markov Property.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Exponential Martingale Property&lt;/strong&gt; 
\(\mathbb{E}[Z(t)|\mathcal{F}(s)] = Z(s), s&amp;lt; t \text{, where } Z(t)=e^{ \sigma W(t)-\frac{1}{2}\sigma^2t }\) 
The exponential martingale is a more common form of Martingale in financial mathematics.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Remark: Stopping time &amp;amp; Reflection Principal&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Markov Property&lt;/strong&gt; 
\(\mathbb{E}[f(W(t)|\mathcal{F}(s)]=g(W(s))\)
where $g(x)$ is defined as below:&lt;/p&gt;

&lt;p&gt;\(g(x) = \mathbb{E}[f(W(t)-W(s)+x)]=\frac{1}{\sqrt{2\pi(t-s)}}\int_{-\infty}^{\infty} f(w+x) e^{-\frac{w^2}{2(t-s)}} dw\)
The process of proof is very important as it introduces &lt;strong&gt;Transition Density&lt;/strong&gt; $p(\tau, x,y)$ which is the probability density from state $x$ to state $y$ with the time period $\tau$. The function $g(x)$ can be rewritten as 
\(g(x)= \frac{1}{\sqrt{2\pi\tau}}\int_{-\infty}^{\infty} f(y) e^{-\frac{(y-x)^2}{2\tau}} dy = \int_{-\infty}^{\infty} f(y)p(\tau, x,y)dy\)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Remark: It links to Stopping time problem. (This will be discussed in an individual post.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;derivative-of-wt&quot;&gt;Derivative of $W(t)$&lt;/h2&gt;

&lt;p&gt;The derivative $\frac{d}{dt}W(t)$ doesn’t exist. Wait! You mentioned that $W(t)$ is normal distributed and normal distribution is continuous!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Please note that the outcome of Brownian Motion $W(t)$ at a time $t$ is normal distributed, NOT the process itself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Brownian Motion or any function of it is the process against the time. Most of the case, the variable time is the base of other variables in the same function, which means other variables depend on the time. This is why the stochastic calculus is different from calculus.&lt;/p&gt;

&lt;p&gt;Then how is the derivative of $W(t)$ defined? The answer is &lt;strong&gt;Quadratic Variation&lt;/strong&gt;. The Quadratic Varitation is defined as below
\(\sum_{j=0}^{n-1}(W(t_{j+1}) - W(t_j) )^2 \text{ with } \Pi = \{ t_0,t_1, ..., t_n \} \text{ as a partition of } [0,T]\)&lt;/p&gt;

&lt;p&gt;One result of quadratic variation is that $(W(t_{j+1}-W(t_j))^2$ follows the Chi-squared distribution with the mean $(t_{j+1}-t_j)$ and the variance $2(t_{j+1}-t_j)^2$ and this gives us informally $dW(t)dW(t) = dt$.&lt;/p&gt;</content><author><name>Yang An</name></author><category term="math" /><summary type="html">Brownian Motion</summary></entry></feed>